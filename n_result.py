# import csv
# import re
# import os

# def extract_model_name(log_filename):
#     """ ä»æ—¥å¿—æ–‡ä»¶åä¸­æå–æ¨¡å‹åç§°ï¼ˆå»æ‰æ‰©å±•å .logï¼‰ """
#     return os.path.splitext(log_filename)[0]  # å»é™¤ .log åç¼€

# def parse_log_file(log_file):
#     """ è§£æå•ä¸ªæ—¥å¿—æ–‡ä»¶ï¼Œæå–å„é¡¹æŒ‡æ ‡ """
#     data = []
#     model_name = extract_model_name(os.path.basename(log_file))  # æå–æ¨¡å‹åç§°
#     with open(log_file, "r", encoding="utf-8") as file:
#         content = file.read()

#     # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å„é¡¹æŒ‡æ ‡
#     metrics = {
#         "Matching Score": re.search(r"========== Matching Score Summary =========.*?Mean: ([\d.]+) CInterval: ([\d.]+)", content, re.S),
#         "FID": re.search(r"========== FID Summary =========.*?Mean: ([\d.]+) CInterval: ([\d.]+)", content, re.S),
#         "Diversity": re.search(r"========== Diversity Summary =========.*?Mean: ([\d.]+) CInterval: ([\d.]+)", content, re.S),
#         "MultiModality": re.search(r"========== MultiModality Summary =========.*?Mean: ([\d.]+) CInterval: ([\d.]+)", content, re.S)
#     }

#     # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… R_precision Summary ä¸­çš„ top k æ•°æ®
#     r_precision_matches = re.findall(r"\(top (\d+)\).*?Mean: ([\d.]+) CInt: ([\d.]+)", content)

#     # å¤„ç†åŒ¹é…åˆ°çš„æŒ‡æ ‡æ•°æ®
#     for metric, match in metrics.items():
#         if match:
#             data.append([model_name, metric, float(match.group(1)), float(match.group(2))])

#     # å¤„ç† R_precisionï¼ˆtop 1, top 2, top 3ï¼‰
#     for match in r_precision_matches:
#         top_k, mean, cint = match
#         data.append([model_name, f"R_precision (top {top_k})", float(mean), float(cint)])

#     return data

# def process_logs_in_directory(log_dir, output_csv):
#     """ éå†ç›®å½•ä¸‹çš„æ‰€æœ‰æ—¥å¿—æ–‡ä»¶å¹¶å†™å…¥ CSV """
#     all_data = [["Action_Types", "Metric", "Mean", "Confidence Interval"]]  # CSV å¤´éƒ¨

#     for filename in os.listdir(log_dir):
#         if filename.endswith(".log"):  # åªå¤„ç† .log æ–‡ä»¶
#             log_path = os.path.join(log_dir, filename)
#             all_data.extend(parse_log_file(log_path))

#     # å†™å…¥ CSV
#     with open(output_csv, mode="w", newline="") as file:
#         writer = csv.writer(file)
#         writer.writerows(all_data)

#     print(f"âœ… CSV æ–‡ä»¶å·²ç”Ÿæˆ: {output_csv}")

# # è®¾ç½®æ—¥å¿—æ–‡ä»¶æ‰€åœ¨ç›®å½•
# log_directory = "//liujinxin/code/text-to-motion/log/hu_GPRO_union15_3-11-21-12-57/checkpoint-36000"  # ğŸ”¹ è¯·ä¿®æ”¹ä¸ºä½ çš„æ—¥å¿—ç›®å½•è·¯å¾„
# output_csv_path = "//liujinxin/code/text-to-motion/log/hu_GPRO_union15_3-11-21-12-57/checkpoint-36000/hu_GPRO_union15_3-11-21-12-57.csv"

# # å¤„ç†æ—¥å¿—æ–‡ä»¶å¹¶ç”Ÿæˆ CSV
# process_logs_in_directory(log_directory, output_csv_path)
import csv
import re
import os

def extract_model_name(log_filename):
    """ ä»æ—¥å¿—æ–‡ä»¶åä¸­æå–æ¨¡å‹åç§°ï¼ˆå»æ‰æ‰©å±•å .logï¼‰ """
    return os.path.splitext(log_filename)[0]  # å»é™¤ .log åç¼€

def parse_log_file(log_file):
    """ è§£æå•ä¸ªæ—¥å¿—æ–‡ä»¶ï¼Œæå–å„é¡¹æŒ‡æ ‡ """
    model_name = extract_model_name(os.path.basename(log_file))  # æå–æ¨¡å‹åç§°
    with open(log_file, "r", encoding="utf-8") as file:
        content = file.read()

    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å„é¡¹æŒ‡æ ‡
    metrics = {
        "Matching Score": re.search(r"========== Matching Score Summary =========.*?Mean: ([\d.]+) CInterval: ([\d.]+)", content, re.S),
        "FID": re.search(r"========== FID Summary =========.*?Mean: ([\d.]+) CInterval: ([\d.]+)", content, re.S),
        "Diversity": re.search(r"========== Diversity Summary =========.*?Mean: ([\d.]+) CInterval: ([\d.]+)", content, re.S),
        "MultiModality": re.search(r"========== MultiModality Summary =========.*?Mean: ([\d.]+) CInterval: ([\d.]+)", content, re.S)
    }

    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… R_precision Summary ä¸­çš„ top k æ•°æ®
    r_precision_matches = re.findall(r"\(top (\d+)\).*?Mean: ([\d.]+) CInt: ([\d.]+)", content)

    # åˆå§‹åŒ–æ•°æ®å­—å…¸
    data = {"Action_Types": model_name}

    # å¤„ç†åŒ¹é…åˆ°çš„æŒ‡æ ‡æ•°æ®
    for metric, match in metrics.items():
        if match:
            data[f"{metric} Mean"] = float(match.group(1))
            data[f"{metric} Confidence Interval"] = float(match.group(2))

    # å¤„ç† R_precisionï¼ˆtop 1, top 2, top 3ï¼‰
    for match in r_precision_matches:
        top_k, mean, cint = match
        data[f"R_precision (top {top_k}) Mean"] = float(mean)
        data[f"R_precision (top {top_k}) Confidence Interval"] = float(cint)

    return data

def process_logs_in_directory(log_dir, output_csv):
    """ éå†ç›®å½•ä¸‹çš„æ‰€æœ‰æ—¥å¿—æ–‡ä»¶å¹¶å†™å…¥ CSV """
    all_data = []

    # è·å–æ‰€æœ‰æ—¥å¿—æ–‡ä»¶çš„æŒ‡æ ‡æ•°æ®
    for filename in os.listdir(log_dir):
        if filename.endswith(".log"):  # åªå¤„ç† .log æ–‡ä»¶
            log_path = os.path.join(log_dir, filename)
            all_data.append(parse_log_file(log_path))

    # è·å–æ‰€æœ‰å¯èƒ½çš„åˆ—å
    columns = set()
    for row in all_data:
        columns.update(row.keys())
    columns = sorted(columns)  # æŒ‰å­—æ¯é¡ºåºæ’åº

    # å†™å…¥ CSV
    with open(output_csv, mode="w", newline="") as file:
        writer = csv.DictWriter(file, fieldnames=columns)
        writer.writeheader()
        writer.writerows(all_data)

    print(f"âœ… CSV æ–‡ä»¶å·²ç”Ÿæˆ: {output_csv}")

# è®¾ç½®æ—¥å¿—æ–‡ä»¶æ‰€åœ¨ç›®å½•
# log_directory = "/liujinxin/code/text-to-motion/log/hu_GPRO_union15_3-17-19-45-28/checkpoint-1000"  # ğŸ”¹ è¯·ä¿®æ”¹ä¸ºä½ çš„æ—¥å¿—ç›®å½•è·¯å¾„
# output_csv_path = "/liujinxin/code/text-to-motion/log/hu_GPRO_union15_3-17-19-45-28/checkpoint-1000/28.csv"
log_directory = "/liujinxin/code/text-to-motion/log/hu_GPRO_union15_3-19-3-5-27/checkpoint-1200"
output_csv_path = '/liujinxin/code/text-to-motion/log/hu_GPRO_union15_3-19-3-5-27/base.csv'
# å¤„ç†æ—¥å¿—æ–‡ä»¶å¹¶ç”Ÿæˆ CSV
process_logs_in_directory(log_directory, output_csv_path)